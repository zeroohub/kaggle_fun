{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# facial keypoints detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os import path as opath\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "import errno\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting \n",
    "DATA_PATH = 'data/'\n",
    "MODEL_PATH = 'models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dorian/WorkSpace/kaggle_fun/facial_keypoints_detector/data\n",
      "downloading https://www.kaggle.com/c/facial-keypoints-detector/download/train.csv\n",
      "\n",
      "train.csv already downloaded !\n",
      "downloading https://www.kaggle.com/c/facial-keypoints-detector/download/test.csv\n",
      "\n",
      "test.csv already downloaded !\n",
      "downloading https://www.kaggle.com/c/facial-keypoints-detector/download/train_identity.csv\n",
      "\n",
      "train_identity.csv already downloaded !\n",
      "\u001b[1m\u001b[36mtest\u001b[m\u001b[m/               \u001b[1m\u001b[36mtrain\u001b[m\u001b[m/              train_identity.csv\n",
      "test.csv            train.csv           \u001b[1m\u001b[36mvalid\u001b[m\u001b[m/\n",
      "/Users/dorian/WorkSpace/kaggle_fun/facial_keypoints_detector\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'/Users/dorian/WorkSpace/kaggle_fun/facial_keypoints_detector'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%mkdir -p $DATA_PATH\n",
    "%pwd\n",
    "%cd $DATA_PATH\n",
    "%pwd\n",
    "!kg download -c facial-keypoints-detector\n",
    "%ls\n",
    "%cd ..\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pixels(pix_str):\n",
    "    return np.array([int(p) for p in pix_str.split(' ')], 'uint8').reshape((48, 48))\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    df = pd.read_csv(opath.join(DATA_PATH, 'train.csv'), converters={'Pixels': convert_pixels})\n",
    "    return df\n",
    "\n",
    "data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_label(df):\n",
    "    df = df.copy()\n",
    "    df.loc[df['Emotion'] == 0, 'Emotion'] = 'anger'\n",
    "    df.loc[df['Emotion'] == 1, 'Emotion'] = 'disgust'\n",
    "    df.loc[df['Emotion'] == 2, 'Emotion'] = 'fear'\n",
    "    df.loc[df['Emotion'] == 3, 'Emotion'] = 'happy'\n",
    "    df.loc[df['Emotion'] == 4, 'Emotion'] = 'sad'\n",
    "    df.loc[df['Emotion'] == 5, 'Emotion'] = 'surprise'\n",
    "    df.loc[df['Emotion'] == 6, 'Emotion'] = 'neutral'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_data = decode_label(data)\n",
    "remove_neutral_data = decoded_data[decoded_data['Emotion'] == 'neutral'].sample(700)\n",
    "remove_happy_data = decoded_data[decoded_data['Emotion'] == 'happy'].sample(300)\n",
    "transformed_data = decoded_data.drop((remove_happy_data+remove_neutral_data).index)\n",
    "test_data = transformed_data.sample(frac=0.1)\n",
    "transformed_data = transformed_data.drop(test_data.index)\n",
    "valid_data = transformed_data.sample(frac=0.2)\n",
    "train_data = transformed_data.drop(valid_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exception:\n",
    "        if exception.errno != errno.EEXIST:\n",
    "            raise\n",
    "            \n",
    "            \n",
    "def save_img_files(df, base):\n",
    "    sub_path = opath.join(DATA_PATH, base)\n",
    "    for idx, row in df.iterrows():\n",
    "        category_path = opath.join(sub_path, row['Emotion'])\n",
    "        mkdir(category_path)\n",
    "        Image.fromarray(row['Pixels']).save(opath.join(category_path, '{}.png'.format(idx)), 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_img_files(test_data, 'test')\n",
    "save_img_files(valid_data, 'valid')\n",
    "save_img_files(train_data, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2288 images belonging to 7 classes.\n",
      "Found 572 images belonging to 7 classes.\n",
      "Found 318 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "from utils.vgg16 import get_batches\n",
    "batch_size = 16\n",
    "train_batches = get_batches(opath.join(DATA_PATH, 'train'), batch_size=batch_size)\n",
    "valid_batches = get_batches(opath.join(DATA_PATH, 'valid'), batch_size=batch_size*2)\n",
    "test_batches = get_batches(opath.join(DATA_PATH, 'test'), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_26 (Conv2D)           (None, 16, 222, 222)      448       \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 32, 220, 220)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 32, 110, 110)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 64, 108, 108)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 64, 54, 54)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 128, 52, 52)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 128, 26, 26)       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 86528)             0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 86528)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 7)                 605703    \n",
      "=================================================================\n",
      "Total params: 703,143\n",
      "Trainable params: 703,143\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import MaxPooling2D, ZeroPadding2D, Conv2D\n",
    "\n",
    "\n",
    "def get_bench_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(3, 224, 224)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(7, activation='relu'))\n",
    "    return model\n",
    "\n",
    "bench_model = get_bench_model()\n",
    "bench_model.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "bench_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "weigths_name = 'bench.weigths.best.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath=opath.join(MODEL_PATH, weigths_name), \n",
    "                               verbose=1, save_best_only=True)\n",
    "bench_model.fit_generator(train_batches, samples_per_epoch=batches.nb_sample, nb_epoch=2, \n",
    "                          validation_data=valid_batches, nb_val_samples=val_batches.nb_sample,\n",
    "                          callbacks=[checkpointer],)\n",
    "bench_model.load_weigths(weigths_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from utils.vgg16 import get_model\n",
    "vgg_model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vgg_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-3debba46acb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvgg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvgg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvgg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RMSprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vgg_model' is not defined"
     ]
    }
   ],
   "source": [
    "vgg_model.pop()\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "vgg_model.add(Dense(7, activation='softmax'))\n",
    "vgg_model.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
