{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Prepare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T07:19:55.764191Z",
     "start_time": "2018-04-12T07:19:55.444294Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from __future__ import division\n",
    "import sys\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T07:20:39.957345Z",
     "start_time": "2018-04-12T07:20:38.977474Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ansible/WorkSpace/miniconda2/envs/kaggle/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.commands import unzip, mkdir, call, count_file, KaggleCLI, execute_in, unzip_all, load_array\n",
    "from utils.plot import plot_images, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T07:20:43.894326Z",
     "start_time": "2018-04-12T07:20:43.848746Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from keras import optimizers, initializers, losses, callbacks, regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T06:59:19.973396Z",
     "start_time": "2018-04-12T06:59:19.903008Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_path = pjoin(os.getcwd(), 'models')\n",
    "cal_path = pjoin(os.getcwd(), 'cal')\n",
    "for p in [model_path, cal_path]:\n",
    "    mkdir(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Things will be done:\n",
    "- examine the data\n",
    "- Collaborative Filtering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T07:20:50.522078Z",
     "start_time": "2018-04-12T07:20:50.378112Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "idx = imdb.get_word_index()\n",
    "idx2word = {v: k for k, v in idx.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T07:21:36.423853Z",
     "start_time": "2018-04-12T07:20:52.023630Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_words = 5000\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(path=\"imdb.npz\",\n",
    "                                                      num_words=num_words,\n",
    "                                                      skip_top=0,\n",
    "                                                      maxlen=None,\n",
    "                                                      seed=113,\n",
    "                                                      start_char=None,\n",
    "                                                      oov_char=5000,\n",
    "                                                      index_from=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T09:22:32.030543Z",
     "start_time": "2018-04-10T09:22:31.983911Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2493 10 237.71364\n"
     ]
    }
   ],
   "source": [
    "lens = np.array(map(len, x_train))\n",
    "print lens.max(), lens.min(), lens.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T07:22:08.549027Z",
     "start_time": "2018-04-12T07:22:07.491201Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "maxlen = 500\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen, value=0)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen, value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple&CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Single hidden layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T09:47:55.142426Z",
     "start_time": "2018-04-10T09:47:54.622883Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16000)             64000     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 300)               4800300   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 5,025,801\n",
      "Trainable params: 4,993,201\n",
      "Non-trainable params: 32,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_simple_nn():\n",
    "    model = Sequential([\n",
    "        Embedding(num_words, 32, input_length=maxlen),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(300, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.7),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "single_model = build_simple_nn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T09:47:59.615685Z",
     "start_time": "2018-04-10T09:47:59.548988Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "single_model.compile(Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T09:49:00.007194Z",
     "start_time": "2018-04-10T09:48:00.891981Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 6s 248us/step - loss: 0.6280 - acc: 0.7170 - val_loss: 0.3255 - val_acc: 0.8617\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 6s 232us/step - loss: 0.2009 - acc: 0.9214 - val_loss: 0.3455 - val_acc: 0.8603\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 6s 231us/step - loss: 0.0743 - acc: 0.9742 - val_loss: 0.4457 - val_acc: 0.8531\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 6s 234us/step - loss: 0.0393 - acc: 0.9866 - val_loss: 0.4771 - val_acc: 0.8525\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 6s 231us/step - loss: 0.0241 - acc: 0.9920 - val_loss: 0.5556 - val_acc: 0.8482\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 6s 231us/step - loss: 0.0231 - acc: 0.9920 - val_loss: 0.6139 - val_acc: 0.8422\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 6s 233us/step - loss: 0.0302 - acc: 0.9892 - val_loss: 0.7393 - val_acc: 0.8378\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 6s 231us/step - loss: 0.0265 - acc: 0.9897 - val_loss: 0.5919 - val_acc: 0.8380\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 6s 232us/step - loss: 0.0224 - acc: 0.9924 - val_loss: 0.6768 - val_acc: 0.8340\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 6s 234us/step - loss: 0.0193 - acc: 0.9931 - val_loss: 0.7872 - val_acc: 0.8399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f10c0270190>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_model.fit(x_train, y_train, batch_size=64, epochs=10, \n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T02:22:23.581652Z",
     "start_time": "2018-04-11T02:22:23.133258Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 500, 32)           128       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 500, 64)           10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 100)               1600100   \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,771,289\n",
      "Trainable params: 1,770,897\n",
      "Non-trainable params: 392\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_simple_cnn():\n",
    "    model = Sequential([\n",
    "        Embedding(num_words, 32, input_length=maxlen),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Conv1D(64, 5, padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        MaxPooling1D(),\n",
    "        Flatten(),\n",
    "        Dropout(0.4),\n",
    "        Dense(100, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.7),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "simple_cnn = build_simple_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T02:22:27.103868Z",
     "start_time": "2018-04-11T02:22:27.015969Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "simple_cnn.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T02:23:10.859729Z",
     "start_time": "2018-04-11T02:22:28.342716Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 9s 373us/step - loss: 0.8076 - acc: 0.5637 - val_loss: 1.8885 - val_acc: 0.6918\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 8s 323us/step - loss: 0.3314 - acc: 0.8634 - val_loss: 0.5376 - val_acc: 0.8596\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 8s 323us/step - loss: 0.2530 - acc: 0.8978 - val_loss: 0.3240 - val_acc: 0.8663\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 8s 322us/step - loss: 0.2100 - acc: 0.9172 - val_loss: 0.3225 - val_acc: 0.8693\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 8s 321us/step - loss: 0.1847 - acc: 0.9291 - val_loss: 0.3065 - val_acc: 0.8756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0fe3e6bc10>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_cnn.fit(x_train, y_train, batch_size=64, epochs=5, \n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### vgg style cnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T10:07:51.533190Z",
     "start_time": "2018-04-10T10:07:50.584358Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 500, 32)           128       \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 500, 16)           2576      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 500, 16)           64        \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 500, 16)           1296      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 500, 16)           64        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 250, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 250, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 250, 32)           128       \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 250, 32)           10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 250, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 125, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 125, 64)           41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 125, 64)           256       \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 125, 64)           81984     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 125, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 62, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 3968)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 3968)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 200)               793800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 1,139,129\n",
      "Trainable params: 1,137,817\n",
      "Non-trainable params: 1,312\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_vgg_cnn():\n",
    "    model = Sequential([\n",
    "        Embedding(num_words, 32, input_length=maxlen),\n",
    "        BatchNormalization(),\n",
    "        Conv1D(16, 5, padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv1D(16, 5, padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(),\n",
    "        Conv1D(32, 10, padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv1D(32, 10, padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(),\n",
    "        Conv1D(64, 20, padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv1D(64, 20, padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(),\n",
    "        Flatten(),\n",
    "        Dropout(0.5),\n",
    "        Dense(200, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(200, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "vgg_cnn = build_vgg_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T10:08:00.629596Z",
     "start_time": "2018-04-10T10:08:00.542865Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vgg_cnn.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T10:09:15.451233Z",
     "start_time": "2018-04-10T10:08:01.703149Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 16s 655us/step - loss: 0.6948 - acc: 0.6240 - val_loss: 0.4778 - val_acc: 0.8078\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 14s 548us/step - loss: 0.3152 - acc: 0.8708 - val_loss: 0.3031 - val_acc: 0.8704\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 14s 552us/step - loss: 0.1925 - acc: 0.9262 - val_loss: 0.9461 - val_acc: 0.7574\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 14s 554us/step - loss: 0.1268 - acc: 0.9519 - val_loss: 0.4214 - val_acc: 0.8560\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 14s 549us/step - loss: 0.0906 - acc: 0.9672 - val_loss: 0.5628 - val_acc: 0.8304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f10a04eb450>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_cnn.fit(x_train, y_train, batch_size=64, epochs=5, \n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning with GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T07:22:23.716732Z",
     "start_time": "2018-04-12T07:22:19.187816Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_glove_dataset(dataset):\n",
    "    \"\"\"Download the requested glove dataset from files.fast.ai\n",
    "    and return a location that can be passed to load_vectors.\n",
    "    \"\"\"\n",
    "    # see wordvectors.ipynb for info on how these files were\n",
    "    # generated from the original glove data.\n",
    "    md5sums = {'6B.50d': '8e1557d1228decbda7db6dfd81cd9909',\n",
    "               '6B.100d': 'c92dbbeacde2b0384a43014885a60b2c',\n",
    "               '6B.200d': 'af271b46c04b0b2e41a84d8cd806178d',\n",
    "               '6B.300d': '30290210376887dcc6d0a5a6374d8255'}\n",
    "    return get_file(dataset,\n",
    "                    'http://files.fast.ai/models/glove/' + dataset + '.tgz',\n",
    "                    md5_hash=md5sums.get(dataset, None),\n",
    "                    untar=True)\n",
    "\n",
    "def load_vectors(loc):\n",
    "    return (load_array(loc+'.dat'),\n",
    "        pickle.load(open(loc+'_words.pkl','rb')),\n",
    "        pickle.load(open(loc+'_idx.pkl','rb')))\n",
    "\n",
    "vecs, words, wordidx = load_vectors(get_glove_dataset('6B.50d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T07:22:30.146102Z",
     "start_time": "2018-04-12T07:22:30.095616Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def create_emb():\n",
    "    n_fact = vecs.shape[1]\n",
    "    emb = np.zeros((num_words, n_fact))    \n",
    "    for i in range(1,len(emb)):\n",
    "        word = idx2word[i]\n",
    "        if word and re.match(r\"^[a-zA-Z0-9\\-]*$\", word):\n",
    "            src_idx = wordidx[word]\n",
    "            emb[i] = vecs[src_idx]\n",
    "        else:\n",
    "            # If we can't find the word in glove, randomly initialize\n",
    "            emb[i] = np.random.normal(scale=0.6, size=(n_fact,))\n",
    "\n",
    "    # This is our \"rare word\" id - we want to randomly initialize\n",
    "    emb[-1] = np.random.normal(scale=0.6, size=(n_fact,))\n",
    "    emb /= 3\n",
    "    return emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T07:27:54.102209Z",
     "start_time": "2018-04-12T07:27:53.647554Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 50)           250000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 500, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 500, 64)           16064     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               1600100   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,866,665\n",
      "Trainable params: 1,616,465\n",
      "Non-trainable params: 250,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SpatialDropout1D\n",
    "\n",
    "def build_glove_cnn():\n",
    "    model = Sequential([\n",
    "        Embedding(num_words, 50, input_length=maxlen, weights=[create_emb()], trainable=False),\n",
    "        SpatialDropout1D(0.2),\n",
    "        Conv1D(64, 5, padding='same', activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        MaxPooling1D(),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "glove_cnn = build_glove_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T07:29:39.980206Z",
     "start_time": "2018-04-12T07:29:39.896241Z"
    }
   },
   "outputs": [],
   "source": [
    "glove_cnn.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T07:29:41.072277Z",
     "start_time": "2018-04-12T07:29:41.032944Z"
    }
   },
   "outputs": [],
   "source": [
    "glove_cnn.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T07:29:37.934361Z",
     "start_time": "2018-04-12T07:29:37.894684Z"
    }
   },
   "outputs": [],
   "source": [
    "glove_cnn.layers[0].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T07:30:04.415916Z",
     "start_time": "2018-04-12T07:29:43.856094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 7s 273us/step - loss: 0.3306 - acc: 0.8553 - val_loss: 0.3697 - val_acc: 0.8349\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 6s 259us/step - loss: 0.2908 - acc: 0.8783 - val_loss: 0.3544 - val_acc: 0.8420\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 6s 259us/step - loss: 0.2658 - acc: 0.8886 - val_loss: 0.3482 - val_acc: 0.8472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc6081477d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_cnn.fit(x_train, y_train, batch_size=64, epochs=3, \n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Size CNN with GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T08:14:02.930206Z",
     "start_time": "2018-04-12T08:14:02.109672Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 500, 50)           250000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_4 (Spatial (None, 500, 50)           0         \n",
      "_________________________________________________________________\n",
      "model_3 (Model)              multiple                  38592     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 48000)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               4800100   \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 5,088,793\n",
      "Trainable params: 4,838,793\n",
      "Non-trainable params: 250,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_mutisize_cnn_glove():\n",
    "    graph_in = Input((num_words, 50))\n",
    "    convs = []\n",
    "    for fsz in range(3, 6):\n",
    "        x = Conv1D(64, fsz, padding='same', activation='relu')(graph_in)\n",
    "        x = MaxPooling1D()(x)\n",
    "        x = Flatten()(x)\n",
    "        convs.append(x)\n",
    "        \n",
    "    out = Concatenate()(convs)\n",
    "    graph = Model(graph_in, out)\n",
    "    \n",
    "    model = Sequential([\n",
    "        Embedding(num_words, 50, input_length=maxlen, weights=[create_emb()], trainable=False),\n",
    "        SpatialDropout1D(0.2),\n",
    "        graph,\n",
    "        Dropout(0.2),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dropout(0.4),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "multisize_cnn_glove = build_mutisize_cnn_glove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T08:18:32.090566Z",
     "start_time": "2018-04-12T08:18:32.006717Z"
    }
   },
   "outputs": [],
   "source": [
    "multisize_cnn_glove.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T08:18:33.082729Z",
     "start_time": "2018-04-12T08:18:33.043570Z"
    }
   },
   "outputs": [],
   "source": [
    "multisize_cnn_glove.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T08:18:26.914451Z",
     "start_time": "2018-04-12T08:18:26.875575Z"
    }
   },
   "outputs": [],
   "source": [
    "multisize_cnn_glove.layers[0].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T08:19:31.527280Z",
     "start_time": "2018-04-12T08:18:41.270706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 10s 416us/step - loss: 0.3342 - acc: 0.8602 - val_loss: 0.3606 - val_acc: 0.8390\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 10s 392us/step - loss: 0.3018 - acc: 0.8752 - val_loss: 0.3414 - val_acc: 0.8502\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 10s 393us/step - loss: 0.2743 - acc: 0.8870 - val_loss: 0.3280 - val_acc: 0.8576\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 10s 392us/step - loss: 0.2517 - acc: 0.8972 - val_loss: 0.3189 - val_acc: 0.8623\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 10s 393us/step - loss: 0.2281 - acc: 0.9118 - val_loss: 0.3127 - val_acc: 0.8673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc58c2c4f10>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multisize_cnn_glove.fit(x_train, y_train, batch_size=64, epochs=5, \n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
