{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nietzsche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T09:58:01.267769Z",
     "start_time": "2018-05-11T09:58:00.905402Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from __future__ import division\n",
    "import sys\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T09:58:04.921867Z",
     "start_time": "2018-05-11T09:58:03.937676Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ansible/WorkSpace/miniconda2/envs/kaggle/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.commands import unzip, mkdir, call, count_file, KaggleCLI, execute_in, unzip_all, load_array\n",
    "from utils.plot import plot_images, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T07:20:43.894326Z",
     "start_time": "2018-04-12T07:20:43.848746Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import optimizers, initializers, losses, callbacks, regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T09:03:07.069382Z",
     "start_time": "2018-05-14T09:03:06.973432Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = pjoin(os.getcwd(), 'models')\n",
    "cal_path = pjoin(os.getcwd(), 'cal')\n",
    "data_path = pjoin(os.getcwd(), 'data')\n",
    "for p in [model_path, cal_path, data_path]:\n",
    "    mkdir(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things will be done:\n",
    "- examine the data\n",
    "- Collaborative Filtering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Examine Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T14:48:09.016274Z",
     "start_time": "2018-05-14T14:48:08.972850Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('corpus length:', 600901)\n"
     ]
    }
   ],
   "source": [
    "nietzsche_path = get_file(pjoin(data_path, 'nietzsche.txt'), origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "text = open(nietzsche_path).read().lower()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T14:48:10.423363Z",
     "start_time": "2018-05-14T14:48:10.365163Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('total chars:', 60)\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)+1\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T14:48:41.379756Z",
     "start_time": "2018-05-14T14:48:41.341369Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chars.insert(0, \"\\0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T14:49:40.234422Z",
     "start_time": "2018-05-14T14:49:40.195846Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T14:49:48.168602Z",
     "start_time": "2018-05-14T14:49:48.043014Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx = [char_indices[c] for c in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Char model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T07:36:33.002895Z",
     "start_time": "2018-05-15T07:36:32.847887Z"
    }
   },
   "outputs": [],
   "source": [
    "cs=3\n",
    "c1_dat = [idx[i] for i in xrange(0, len(idx)-1-cs, cs)]\n",
    "c2_dat = [idx[i+1] for i in xrange(0, len(idx)-1-cs, cs)]\n",
    "c3_dat = [idx[i+2] for i in xrange(0, len(idx)-1-cs, cs)]\n",
    "c4_dat = [idx[i+3] for i in xrange(0, len(idx)-1-cs, cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T07:36:53.409347Z",
     "start_time": "2018-05-15T07:36:52.308015Z"
    }
   },
   "outputs": [],
   "source": [
    "x1 = np.stack(c1_dat[:-2])\n",
    "x2 = np.stack(c2_dat[:-2])\n",
    "x3 = np.stack(c3_dat[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T07:36:55.342651Z",
     "start_time": "2018-05-15T07:36:54.836785Z"
    }
   },
   "outputs": [],
   "source": [
    "y = np.stack(c4_dat[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T07:38:02.324374Z",
     "start_time": "2018-05-15T07:38:02.279370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200297,), (200297,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T07:38:39.118885Z",
     "start_time": "2018-05-15T07:38:39.082674Z"
    }
   },
   "outputs": [],
   "source": [
    "n_fac = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T07:38:37.811469Z",
     "start_time": "2018-05-15T07:38:37.770183Z"
    }
   },
   "outputs": [],
   "source": [
    "def embedding_input(name, n_in, n_out):\n",
    "    inp = Input(shape=(1,), dtype='int64', name=name)\n",
    "    emb = Embedding(n_in, n_out, input_length=1)(inp)\n",
    "    return inp, Flatten()(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T08:03:51.427263Z",
     "start_time": "2018-05-15T08:03:51.372900Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    c1_in, c1 = embedding_input('c1', vocab_size, n_fac)\n",
    "    c2_in, c2 = embedding_input('c2', vocab_size, n_fac)\n",
    "    c3_in, c3 = embedding_input('c3', vocab_size, n_fac)\n",
    "    n_hidden = 256\n",
    "    dense_in = Dense(n_hidden, activation='relu')\n",
    "    c1_hidden = dense_in(c1)\n",
    "    dense_hidden = Dense(n_hidden, activation='tanh')\n",
    "    c2_dense = dense_in(c2)\n",
    "    hidden_2 = dense_hidden(c1_hidden)\n",
    "    c2_hidden = add([c2_dense, hidden_2])\n",
    "    c3_dense = dense_in(c3)\n",
    "    hidden_3 = dense_hidden(c2_hidden)\n",
    "    c3_hidden = add([c3_dense, hidden_3])\n",
    "    dense_out = Dense(vocab_size, activation='softmax')\n",
    "    c4_out = dense_out(c3_hidden)\n",
    "    model = Model([c1_in, c2_in, c3_in], c4_out)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T08:04:10.741273Z",
     "start_time": "2018-05-15T08:04:10.604038Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "c3 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "c2 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "c1 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 42)        2520        c3[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 42)        2520        c2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 42)        2520        c1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 42)           0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 42)           0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 42)           0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          11008       flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          65792       dense_4[0][0]                    \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 256)          0           dense_4[1][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 256)          0           dense_4[2][0]                    \n",
      "                                                                 dense_5[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 60)           15420       add_2[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 99,780\n",
      "Trainable params: 99,780\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T08:06:44.739752Z",
     "start_time": "2018-05-15T08:06:44.665127Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T08:08:36.568584Z",
     "start_time": "2018-05-15T08:08:36.531720Z"
    }
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T08:16:24.965234Z",
     "start_time": "2018-05-15T08:15:49.455540Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "200297/200297 [==============================] - 18s 88us/step - loss: 2.9182\n",
      "Epoch 2/2\n",
      "200297/200297 [==============================] - 18s 89us/step - loss: 2.9092\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc5d064c150>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x1, x2, x3], y, batch_size=64, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T08:15:35.168103Z",
     "start_time": "2018-05-15T08:15:35.130233Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arrs = [np.array(i)[np.newaxis] for i in idxs]\n",
    "    p = model.predict(arrs)\n",
    "    i = np.argmax(p)\n",
    "    print p\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T08:16:29.477887Z",
     "start_time": "2018-05-15T08:16:29.430718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.2997031e-05 1.8171364e-02 1.4069039e-01 9.6882787e-04 3.4457706e-03\n",
      "  9.0932008e-04 9.8842301e-04 7.8110170e-04 1.4814359e-02 6.0691959e-03\n",
      "  4.5543658e-03 3.9032366e-04 7.1722944e-04 5.8181753e-04 3.5035130e-04\n",
      "  5.4594805e-04 3.6692247e-04 3.9727314e-04 3.4844701e-04 4.6172782e-04\n",
      "  4.3405278e-04 1.3395956e-03 1.0439394e-03 8.1541127e-04 8.1566209e-04\n",
      "  3.6907539e-04 5.4672227e-04 4.3422455e-04 5.7191640e-02 1.0186880e-02\n",
      "  2.5405670e-02 2.9190332e-02 6.8853617e-02 2.0593097e-02 1.6171008e-02\n",
      "  3.8188253e-02 5.2083887e-02 1.1933282e-03 3.8709529e-03 3.8820442e-02\n",
      "  2.3379019e-02 7.2514832e-02 5.0109845e-02 1.7737854e-02 1.2640647e-03\n",
      "  5.2034501e-02 6.9485784e-02 8.2972579e-02 2.4765655e-02 9.8944064e-03\n",
      "  1.5418286e-02 1.5088248e-03 1.4511505e-02 6.3333230e-04 4.3214015e-05\n",
      "  9.6541706e-05 5.8430858e-05 1.3512808e-04 6.0315469e-05 2.1192963e-04]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('phi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:44:13.833988Z",
     "start_time": "2018-05-15T09:44:10.506300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('nb sequences:', 600862)\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(idx) - maxlen+1):\n",
    "    sentences.append(idx[i: i + maxlen])\n",
    "    next_chars.append(idx[i+1: i+maxlen+1])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:44:41.695359Z",
     "start_time": "2018-05-15T09:44:34.610929Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences = np.concatenate([[np.array(o)] for o in sentences[:-2]])\n",
    "next_chars = np.concatenate([[np.array(o)] for o in next_chars[:-2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:01:55.785040Z",
     "start_time": "2018-05-15T10:01:54.243237Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (20, 40, 42)              2520      \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (20, 40, 512)             1136640   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (20, 40, 512)             0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (20, 40, 512)             2099200   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (20, 40, 512)             0         \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (20, 40, 60)              30780     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (20, 40, 60)              0         \n",
      "=================================================================\n",
      "Total params: 3,269,140\n",
      "Trainable params: 3,269,140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_simple_cnn():\n",
    "    model=Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=maxlen, batch_input_shape=(20, maxlen)),\n",
    "        LSTM(512, activation='relu', recurrent_activation='relu', dropout=0.1, recurrent_dropout=0.1,\n",
    "             stateful=True, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(512, activation='relu', recurrent_activation='relu', dropout=0.1, recurrent_dropout=0.1,\n",
    "             stateful=True, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(vocab_size)),\n",
    "        Activation('softmax')\n",
    "    ])    \n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "simple_rnn = build_simple_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:01:58.422294Z",
     "start_time": "2018-05-15T10:01:58.340119Z"
    }
   },
   "outputs": [],
   "source": [
    "simple_rnn.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:59:12.542558Z",
     "start_time": "2018-05-15T09:59:12.497027Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_example():\n",
    "    seed_string=\"ethics is a basic foundation of all that\"\n",
    "    for i in range(320):\n",
    "        x=np.array([char_indices[c] for c in seed_string[-40:]])[np.newaxis,:]\n",
    "        preds = model.predict(x, verbose=0)[0][-1]\n",
    "        preds = preds/np.sum(preds)\n",
    "        next_char = choice(chars, p=preds)\n",
    "        seed_string = seed_string + next_char\n",
    "    print(seed_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T11:18:53.756766Z",
     "start_time": "2018-05-15T10:02:00.239247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "600860/600860 [==============================] - 4612s 8ms/step - loss: 4.0943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc553274a50>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_rnn.fit(sentences, np.expand_dims(next_chars,-1), batch_size=20, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T13:30:32.693542Z",
     "start_time": "2018-05-15T13:30:32.603595Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model : the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 3 array(s), but instead got the following list of 1 arrays: [array([[32, 47, 35, 36, 30, 46,  2, 36, 46,  2, 28,  2, 29, 28, 46, 36,\n        30,  2, 33, 42, 48, 41, 31, 28, 47, 36, 42, 41,  2, 42, 33,  2,\n        28, 39, 39,  2, 47, 35, 28, 47]])]...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-bbdb6167c41c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-66-66059e104d05>\u001b[0m in \u001b[0;36mprint_example\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseed_string\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mnext_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ansible/WorkSpace/miniconda2/envs/kaggle/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1822\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1823\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1824\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1825\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1826\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ansible/WorkSpace/miniconda2/envs/kaggle/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model : the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 3 array(s), but instead got the following list of 1 arrays: [array([[32, 47, 35, 36, 30, 46,  2, 36, 46,  2, 28,  2, 29, 28, 46, 36,\n        30,  2, 33, 42, 48, 41, 31, 28, 47, 36, 42, 41,  2, 42, 33,  2,\n        28, 39, 39,  2, 47, 35, 28, 47]])]..."
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### vgg style cnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T10:07:51.533190Z",
     "start_time": "2018-04-10T10:07:50.584358Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 500, 32)           128       \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 500, 16)           2576      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 500, 16)           64        \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 500, 16)           1296      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 500, 16)           64        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 250, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 250, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 250, 32)           128       \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 250, 32)           10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 250, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 125, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 125, 64)           41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 125, 64)           256       \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 125, 64)           81984     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 125, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 62, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 3968)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 3968)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 200)               793800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 1,139,129\n",
      "Trainable params: 1,137,817\n",
      "Non-trainable params: 1,312\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_vgg_cnn():\n",
    "    model = Sequential([\n",
    "        Embedding(num_words, 32, input_length=maxlen),\n",
    "        BatchNormalization(),\n",
    "        Conv1D(16, 5, padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv1D(16, 5, padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(),\n",
    "        Conv1D(32, 10, padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv1D(32, 10, padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(),\n",
    "        Conv1D(64, 20, padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv1D(64, 20, padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(),\n",
    "        Flatten(),\n",
    "        Dropout(0.5),\n",
    "        Dense(200, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(200, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "vgg_cnn = build_vgg_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T10:08:00.629596Z",
     "start_time": "2018-04-10T10:08:00.542865Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vgg_cnn.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T10:09:15.451233Z",
     "start_time": "2018-04-10T10:08:01.703149Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 16s 655us/step - loss: 0.6948 - acc: 0.6240 - val_loss: 0.4778 - val_acc: 0.8078\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 14s 548us/step - loss: 0.3152 - acc: 0.8708 - val_loss: 0.3031 - val_acc: 0.8704\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 14s 552us/step - loss: 0.1925 - acc: 0.9262 - val_loss: 0.9461 - val_acc: 0.7574\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 14s 554us/step - loss: 0.1268 - acc: 0.9519 - val_loss: 0.4214 - val_acc: 0.8560\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 14s 549us/step - loss: 0.0906 - acc: 0.9672 - val_loss: 0.5628 - val_acc: 0.8304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f10a04eb450>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_cnn.fit(x_train, y_train, batch_size=64, epochs=5, \n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning with GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T07:22:23.716732Z",
     "start_time": "2018-04-12T07:22:19.187816Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_glove_dataset(dataset):\n",
    "    \"\"\"Download the requested glove dataset from files.fast.ai\n",
    "    and return a location that can be passed to load_vectors.\n",
    "    \"\"\"\n",
    "    # see wordvectors.ipynb for info on how these files were\n",
    "    # generated from the original glove data.\n",
    "    md5sums = {'6B.50d': '8e1557d1228decbda7db6dfd81cd9909',\n",
    "               '6B.100d': 'c92dbbeacde2b0384a43014885a60b2c',\n",
    "               '6B.200d': 'af271b46c04b0b2e41a84d8cd806178d',\n",
    "               '6B.300d': '30290210376887dcc6d0a5a6374d8255'}\n",
    "    return get_file(dataset,\n",
    "                    'http://files.fast.ai/models/glove/' + dataset + '.tgz',\n",
    "                    md5_hash=md5sums.get(dataset, None),\n",
    "                    untar=True)\n",
    "\n",
    "def load_vectors(loc):\n",
    "    return (load_array(loc+'.dat'),\n",
    "        pickle.load(open(loc+'_words.pkl','rb')),\n",
    "        pickle.load(open(loc+'_idx.pkl','rb')))\n",
    "\n",
    "vecs, words, wordidx = load_vectors(get_glove_dataset('6B.50d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T07:22:30.146102Z",
     "start_time": "2018-04-12T07:22:30.095616Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def create_emb():\n",
    "    n_fact = vecs.shape[1]\n",
    "    emb = np.zeros((num_words, n_fact))    \n",
    "    for i in range(1,len(emb)):\n",
    "        word = idx2word[i]\n",
    "        if word and re.match(r\"^[a-zA-Z0-9\\-]*$\", word):\n",
    "            src_idx = wordidx[word]\n",
    "            emb[i] = vecs[src_idx]\n",
    "        else:\n",
    "            # If we can't find the word in glove, randomly initialize\n",
    "            emb[i] = np.random.normal(scale=0.6, size=(n_fact,))\n",
    "\n",
    "    # This is our \"rare word\" id - we want to randomly initialize\n",
    "    emb[-1] = np.random.normal(scale=0.6, size=(n_fact,))\n",
    "    emb /= 3\n",
    "    return emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T07:27:54.102209Z",
     "start_time": "2018-04-12T07:27:53.647554Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 50)           250000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 500, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 500, 64)           16064     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               1600100   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,866,665\n",
      "Trainable params: 1,616,465\n",
      "Non-trainable params: 250,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SpatialDropout1D\n",
    "\n",
    "def build_glove_cnn():\n",
    "    model = Sequential([\n",
    "        Embedding(num_words, 50, input_length=maxlen, weights=[create_emb()], trainable=False),\n",
    "        SpatialDropout1D(0.2),\n",
    "        Conv1D(64, 5, padding='same', activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        MaxPooling1D(),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "glove_cnn = build_glove_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T07:29:39.980206Z",
     "start_time": "2018-04-12T07:29:39.896241Z"
    }
   },
   "outputs": [],
   "source": [
    "glove_cnn.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T07:29:41.072277Z",
     "start_time": "2018-04-12T07:29:41.032944Z"
    }
   },
   "outputs": [],
   "source": [
    "glove_cnn.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T07:29:37.934361Z",
     "start_time": "2018-04-12T07:29:37.894684Z"
    }
   },
   "outputs": [],
   "source": [
    "glove_cnn.layers[0].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T07:30:04.415916Z",
     "start_time": "2018-04-12T07:29:43.856094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 7s 273us/step - loss: 0.3306 - acc: 0.8553 - val_loss: 0.3697 - val_acc: 0.8349\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 6s 259us/step - loss: 0.2908 - acc: 0.8783 - val_loss: 0.3544 - val_acc: 0.8420\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 6s 259us/step - loss: 0.2658 - acc: 0.8886 - val_loss: 0.3482 - val_acc: 0.8472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc6081477d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_cnn.fit(x_train, y_train, batch_size=64, epochs=3, \n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Size CNN with GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T08:14:02.930206Z",
     "start_time": "2018-04-12T08:14:02.109672Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 500, 50)           250000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_4 (Spatial (None, 500, 50)           0         \n",
      "_________________________________________________________________\n",
      "model_3 (Model)              multiple                  38592     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 48000)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               4800100   \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 5,088,793\n",
      "Trainable params: 4,838,793\n",
      "Non-trainable params: 250,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_mutisize_cnn_glove():\n",
    "    graph_in = Input((num_words, 50))\n",
    "    convs = []\n",
    "    for fsz in range(3, 6):\n",
    "        x = Conv1D(64, fsz, padding='same', activation='relu')(graph_in)\n",
    "        x = MaxPooling1D()(x)\n",
    "        x = Flatten()(x)\n",
    "        convs.append(x)\n",
    "        \n",
    "    out = Concatenate()(convs)\n",
    "    graph = Model(graph_in, out)\n",
    "    \n",
    "    model = Sequential([\n",
    "        Embedding(num_words, 50, input_length=maxlen, weights=[create_emb()], trainable=False),\n",
    "        SpatialDropout1D(0.2),\n",
    "        graph,\n",
    "        Dropout(0.2),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dropout(0.4),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "multisize_cnn_glove = build_mutisize_cnn_glove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T08:18:32.090566Z",
     "start_time": "2018-04-12T08:18:32.006717Z"
    }
   },
   "outputs": [],
   "source": [
    "multisize_cnn_glove.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T08:18:33.082729Z",
     "start_time": "2018-04-12T08:18:33.043570Z"
    }
   },
   "outputs": [],
   "source": [
    "multisize_cnn_glove.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T08:18:26.914451Z",
     "start_time": "2018-04-12T08:18:26.875575Z"
    }
   },
   "outputs": [],
   "source": [
    "multisize_cnn_glove.layers[0].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T08:19:31.527280Z",
     "start_time": "2018-04-12T08:18:41.270706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 10s 416us/step - loss: 0.3342 - acc: 0.8602 - val_loss: 0.3606 - val_acc: 0.8390\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 10s 392us/step - loss: 0.3018 - acc: 0.8752 - val_loss: 0.3414 - val_acc: 0.8502\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 10s 393us/step - loss: 0.2743 - acc: 0.8870 - val_loss: 0.3280 - val_acc: 0.8576\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 10s 392us/step - loss: 0.2517 - acc: 0.8972 - val_loss: 0.3189 - val_acc: 0.8623\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 10s 393us/step - loss: 0.2281 - acc: 0.9118 - val_loss: 0.3127 - val_acc: 0.8673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc58c2c4f10>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multisize_cnn_glove.fit(x_train, y_train, batch_size=64, epochs=5, \n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
